{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.65.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages to install\n",
    "# pip install openai requests pydantic\n",
    "\n",
    "# Required imports\n",
    "import json\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "from openai import OpenAI  # For chat completions API\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=\"your-openai-api-key\")  \n",
    "\n",
    "# For the vision model, you need either:\n",
    "# Option 1: If using OpenAI's Vision model\n",
    "# (already included in the OpenAI package)\n",
    "\n",
    "# Option 2: If using another vision model like Google's Vertex AI\n",
    "# pip install google-cloud-aiplatform\n",
    "# from vertexai.vision_models import ImageCaptioningModel\n",
    "# vision_model = ImageCaptioningModel.from_pretrained(\"your-model-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for product search parameters\n",
    "class AmazonSearchQuery(BaseModel):\n",
    "    product_name: str = Field(..., description=\"Main product name extracted from the image\")\n",
    "    brand: Optional[str] = Field(None, description=\"Brand name if visible in the image\")\n",
    "    product_size: Optional[str] = Field(None, description=\"Size/amount/weight information (e.g., '16oz', '500ml')\")\n",
    "    identifiers: Optional[Dict[str, str]] = Field(None, description=\"Product identifiers such as UPC, EAN, ASIN if visible\")\n",
    "    key_features: Optional[List[str]] = Field(None, description=\"Key product features or descriptors visible in the image\")\n",
    "    \n",
    "# Define the schema for Amazon search results verification\n",
    "class ProductVerification(BaseModel):\n",
    "    match_found: bool = Field(..., description=\"Whether a matching product was found on Amazon\")\n",
    "    confidence_score: float = Field(..., description=\"Confidence score for the match (0-1)\")\n",
    "    matched_product: Optional[Dict] = Field(None, description=\"Details of the matched product\")\n",
    "    discrepancies: Optional[List[str]] = Field(None, description=\"List of discrepancies between image and found product\")\n",
    "    amazon_link: Optional[str] = Field(None, description=\"Link to the Amazon product page if found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_search(search_parameters):\n",
    "    \"\"\"\n",
    "    Search Amazon for products matching parameters extracted from a product image.\n",
    "    \n",
    "    Input: Structured data from VLM image analysis\n",
    "    Output: Top matching Amazon products with detailed information\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    \n",
    "    api_key = \"FB0C32E1DCB3433C997C0A0FB1E70608\"\n",
    "    base_url = \"https://api.rainforestapi.com/request\"\n",
    "    \n",
    "    # Configure request parameters\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"amazon_domain\": \"amazon.com\"\n",
    "    }\n",
    "    \n",
    "    # Determine search approach based on available information\n",
    "    if \"asin\" in search_parameters and search_parameters[\"asin\"]:\n",
    "        # Direct ASIN lookup if available\n",
    "        params[\"type\"] = \"product\"\n",
    "        params[\"asin\"] = search_parameters[\"asin\"]\n",
    "    elif \"upc\" in search_parameters or \"ean\" in search_parameters or \"isbn\" in search_parameters:\n",
    "        # GTIN/UPC/EAN lookup\n",
    "        params[\"type\"] = \"product\"\n",
    "        params[\"gtin\"] = search_parameters.get(\"upc\") or search_parameters.get(\"ean\") or search_parameters.get(\"isbn\")\n",
    "    else:\n",
    "        # Text-based search using extracted information\n",
    "        params[\"type\"] = \"search\"\n",
    "        \n",
    "        # Construct search term from product name and attributes\n",
    "        search_term = search_parameters[\"product_name\"]\n",
    "        if \"brand\" in search_parameters:\n",
    "            search_term = f\"{search_parameters['brand']} {search_term}\"\n",
    "        if \"attributes\" in search_parameters:\n",
    "            for key, value in search_parameters[\"attributes\"].items():\n",
    "                search_term += f\" {value}\"\n",
    "        \n",
    "        params[\"search_term\"] = search_term\n",
    "    \n",
    "    # Make API request\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        data = response.json()\n",
    "        \n",
    "        # Process results based on request type\n",
    "        results = []\n",
    "        if params[\"type\"] == \"product\":\n",
    "            if \"product\" in data:\n",
    "                product = data[\"product\"]\n",
    "                results.append({\n",
    "                    \"asin\": product.get(\"asin\"),\n",
    "                    \"title\": product.get(\"title\"),\n",
    "                    \"brand\": product.get(\"brand\"),\n",
    "                    \"price\": product.get(\"buybox_winner\", {}).get(\"price\"),\n",
    "                    \"rating\": product.get(\"rating\"),\n",
    "                    \"ratings_total\": product.get(\"ratings_total\"),\n",
    "                    \"main_image\": product.get(\"main_image\", {}).get(\"link\"),\n",
    "                    \"link\": product.get(\"link\"),\n",
    "                    \"dimensions\": product.get(\"dimensions\"),\n",
    "                    \"weight\": product.get(\"weight\")\n",
    "                })\n",
    "        elif params[\"type\"] == \"search\":\n",
    "            for item in data.get(\"search_results\", [])[:5]:  # Limit to top 5 results\n",
    "                results.append({\n",
    "                    \"asin\": item.get(\"asin\"),\n",
    "                    \"title\": item.get(\"title\"),\n",
    "                    \"link\": item.get(\"link\"),\n",
    "                    \"image\": item.get(\"image\"),\n",
    "                    \"price\": item.get(\"price\")\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            \"query_info\": search_parameters,\n",
    "            \"results\": results\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Handle any errors\n",
    "        return {\n",
    "            \"query_info\": search_parameters,\n",
    "            \"error\": str(e),\n",
    "            \"results\": []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_details_from_image_mixtral(image_path, client, model_id=\"accounts/fireworks/models/mixtral-8x7b-instruct\", timing=None):\n",
    "    \"\"\"\n",
    "    Extract product details from an image using document inlining and a specified model.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): Path to the product image file\n",
    "    client: API client (OpenAI or compatible)\n",
    "    model_id (str): Model ID to use for extraction\n",
    "    timing (dict, optional): Timing dictionary to update with performance metrics\n",
    "    \n",
    "    Returns:\n",
    "    dict: Extracted product details\n",
    "    \"\"\"\n",
    "    import base64\n",
    "    import time\n",
    "    import json\n",
    "    \n",
    "    # Track timing if requested\n",
    "    if timing is not None:\n",
    "        image_prep_start = time.time()\n",
    "    \n",
    "    # Prepare image for document inlining\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "        \n",
    "    base64_image = base64.b64encode(image_content).decode('utf-8')\n",
    "    \n",
    "    # Determine MIME type based on file extension\n",
    "    if image_path.lower().endswith('.jpg') or image_path.lower().endswith('.jpeg'):\n",
    "        mime_type = \"image/jpeg\"\n",
    "    elif image_path.lower().endswith('.png'):\n",
    "        mime_type = \"image/png\"\n",
    "    else:\n",
    "        mime_type = \"image/jpeg\"  # Default to JPEG\n",
    "    \n",
    "    # Create image URL with document inlining transform\n",
    "    image_url = f\"data:{mime_type};base64,{base64_image}#transform=inline\"\n",
    "    \n",
    "    if timing is not None:\n",
    "        timing['image_preparation'] = time.time() - image_prep_start\n",
    "        extract_start = time.time()\n",
    "    \n",
    "    # Extract product details from image using document inlining\n",
    "    extract_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Extract detailed product information from the image. Include product name, brand, size/weight, and any visible identifiers like UPC or model numbers.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            {\"type\": \"text\", \"text\": \"What product is shown in this image? Extract all visible details including product name, brand, size/weight, and any identifiers.\"}\n",
    "        ]}\n",
    "    ]\n",
    "    \n",
    "    # Use document inlining to extract product details with JSON output\n",
    "    extract_response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=extract_messages,\n",
    "        response_format={\"type\": \"json_object\", \"schema\": AmazonSearchQuery.model_json_schema()},\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Parse extracted product details\n",
    "    product_details = json.loads(extract_response.choices[0].message.content)\n",
    "    \n",
    "    if timing is not None:\n",
    "        timing['product_extraction'] = time.time() - extract_start\n",
    "    \n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_details_from_image_firesearch(image_path, client, timing=None):\n",
    "    \"\"\"\n",
    "    Extract product details from an image using the firesearch-ocr-v6 model.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): Path to the product image file\n",
    "    client: API client (OpenAI compatible)\n",
    "    timing (dict, optional): Timing dictionary to update with performance metrics\n",
    "    \n",
    "    Returns:\n",
    "    dict: Extracted product details\n",
    "    \"\"\"\n",
    "    import base64\n",
    "    import time\n",
    "    import json\n",
    "    \n",
    "    # Track timing if requested\n",
    "    if timing is not None:\n",
    "        image_prep_start = time.time()\n",
    "    \n",
    "    # Encode image to base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Determine MIME type based on file extension\n",
    "    if image_path.lower().endswith('.jpg') or image_path.lower().endswith('.jpeg'):\n",
    "        mime_type = \"image/jpeg\"\n",
    "    elif image_path.lower().endswith('.png'):\n",
    "        mime_type = \"image/png\"\n",
    "    else:\n",
    "        mime_type = \"image/jpeg\"  # Default to JPEG\n",
    "        \n",
    "    if timing is not None:\n",
    "        timing['image_preparation'] = time.time() - image_prep_start\n",
    "        extract_start = time.time()\n",
    "    \n",
    "    # Extract product details using firesearch-ocr-v6 model\n",
    "    extract_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an OCR and product information extraction assistant. Extract detailed product information from the image. Include product name, brand, size/weight, and any visible identifiers like UPC, EAN, or model numbers.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Extract all product information visible in this image. Include the product name, brand, size/weight, and any identifiers like UPC, EAN, or model numbers. Format your response as JSON.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    ]\n",
    "    \n",
    "    # Make API call to firesearch-ocr model\n",
    "    extract_response = client.chat.completions.create(\n",
    "        model=\"accounts/fireworks/models/phi-3-vision-128k-instruct\",\n",
    "        messages=extract_messages,\n",
    "        response_format={\"type\": \"json_object\", \"schema\": AmazonSearchQuery.model_json_schema()},\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Parse extracted product details\n",
    "    product_details = json.loads(extract_response.choices[0].message.content)\n",
    "    \n",
    "    if timing is not None:\n",
    "        timing['product_extraction'] = time.time() - extract_start\n",
    "    \n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_product_image(image_path, api_key):\n",
    "    \"\"\"\n",
    "    Process a product image using document inlining and JSON mode\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): Path to the product image file\n",
    "    api_key (str): Fireworks API key\n",
    "    \n",
    "    Returns:\n",
    "    dict: Product verification results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import json\n",
    "    \n",
    "    # Track timing information\n",
    "    timing = {}\n",
    "    start_total = time.time()\n",
    "    \n",
    "    print(f\"\\n🔍 Processing image: {image_path}...\")\n",
    "    \n",
    "    # Initialize client\n",
    "    client_start = time.time()\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    timing['client_initialization'] = time.time() - client_start\n",
    "    \n",
    "    # Extract product details from the image\n",
    "    extract_start = time.time()\n",
    "    print(f\"📷 Analyzing image with AI... \")\n",
    "    product_details = extract_product_details_from_image_mixtral(\n",
    "        image_path=image_path,\n",
    "        client=client,\n",
    "        timing=timing\n",
    "    )\n",
    "    extract_time = time.time() - extract_start\n",
    "    \n",
    "    # Display extracted information\n",
    "    print(f\"✅ Image analyzed in {extract_time:.2f}s\")\n",
    "    print(f\"   Product: {product_details.get('brand', 'Unknown brand')} {product_details.get('product_name', 'Unknown product')}\")\n",
    "    if product_details.get('product_size'):\n",
    "        print(f\"   Size: {product_details.get('product_size')}\")\n",
    "    \n",
    "    # Execute Amazon search using Rainforest API\n",
    "    search_start = time.time()\n",
    "    print(f\"\\n🔎 Searching Amazon for matching products...\")\n",
    "    amazon_results = amazon_search(product_details)\n",
    "    search_time = time.time() - search_start\n",
    "    print(f\"✅ Amazon search completed in {search_time:.2f}s\")\n",
    "    timing['amazon_search'] = search_time\n",
    "    \n",
    "    # Verify product match with LLM using JSON mode\n",
    "    verify_start = time.time()\n",
    "    print(f\"\\n⚖️ Verifying matches...\")\n",
    "    verification_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Analyze the Amazon product results and determine how well they match the original product details. Assign a confidence score (0-1) to each result based on how closely it matches.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Compare these product details:\\n\\nOriginal product: {json.dumps(product_details)}\\n\\nAmazon results: {json.dumps(amazon_results)}\\n\\nFor each result, provide a confidence score and list any discrepancies. Rank them from best match to worst.\"}\n",
    "    ]\n",
    "    \n",
    "    verification_response = client.chat.completions.create(\n",
    "        model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "        messages=verification_messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Parse verification results\n",
    "    llm_verification = json.loads(verification_response.choices[0].message.content)\n",
    "    verification_time = time.time() - verify_start\n",
    "    print(f\"✅ Verification completed in {verification_time:.2f}s\")\n",
    "    timing['verification'] = verification_time\n",
    "    \n",
    "    # Process and enhance the results with direct information from the Amazon API\n",
    "    processing_start = time.time()\n",
    "    print(f\"\\n🏁 Processing final results...\")\n",
    "    \n",
    "    # Create the final output structure\n",
    "    final_results = {\n",
    "        \"match_found\": False,\n",
    "        \"top_match\": None,\n",
    "        \"discrepancies\": [],\n",
    "        \"timing\": timing\n",
    "    }\n",
    "    \n",
    "    # If we have matches to process\n",
    "    if amazon_results.get(\"results\") and len(amazon_results[\"results\"]) > 0:\n",
    "        # Extract confidence scores from LLM verification\n",
    "        matches = []\n",
    "        for idx, result in enumerate(amazon_results[\"results\"]):\n",
    "            # Get or estimate the confidence score \n",
    "            confidence = 0.0\n",
    "            discrepancies = []\n",
    "            \n",
    "            # Try to find this result in the LLM verification\n",
    "            if \"ranked_matches\" in llm_verification:\n",
    "                for match in llm_verification[\"ranked_matches\"]:\n",
    "                    if match.get(\"asin\") == result.get(\"asin\"):\n",
    "                        confidence = match.get(\"confidence_score\", 0.0)\n",
    "                        discrepancies = match.get(\"discrepancies\", [])\n",
    "                        break\n",
    "            \n",
    "            matches.append({\n",
    "                \"confidence_score\": confidence,\n",
    "                \"product_data\": result,\n",
    "                \"discrepancies\": discrepancies\n",
    "            })\n",
    "        \n",
    "        # Sort matches by confidence score in descending order\n",
    "        matches.sort(key=lambda x: x[\"confidence_score\"], reverse=True)\n",
    "        \n",
    "        # Set match_found if we have at least one high-confidence match\n",
    "        if matches and matches[0][\"confidence_score\"] >= 0.7:\n",
    "            final_results[\"match_found\"] = True\n",
    "            \n",
    "        # Add only the top match to final results\n",
    "        if matches:\n",
    "            top_match = matches[0]\n",
    "            match_info = {\n",
    "                \"title\": top_match[\"product_data\"].get(\"title\", \"\"),\n",
    "                \"asin\": top_match[\"product_data\"].get(\"asin\", \"\"),\n",
    "                \"price\": top_match[\"product_data\"].get(\"price\", \"\"),\n",
    "                \"discrepancies\": top_match[\"discrepancies\"],\n",
    "                \"link\": top_match[\"product_data\"].get(\"link\", \"\"),\n",
    "                \"image\": top_match[\"product_data\"].get(\"main_image\", top_match[\"product_data\"].get(\"image\", \"\"))\n",
    "            }\n",
    "            \n",
    "            # Add additional fields if available\n",
    "            for field in [\"brand\", \"rating\", \"ratings_total\", \"dimensions\", \"weight\"]:\n",
    "                if field in top_match[\"product_data\"] and top_match[\"product_data\"][field]:\n",
    "                    match_info[field] = top_match[\"product_data\"][field]\n",
    "                    \n",
    "            final_results[\"top_match\"] = match_info\n",
    "            \n",
    "        # Add overall discrepancies from LLM\n",
    "        if \"general_discrepancies\" in llm_verification:\n",
    "            final_results[\"discrepancies\"] = llm_verification[\"general_discrepancies\"]\n",
    "    \n",
    "    timing['results_processing'] = time.time() - processing_start\n",
    "    timing['total_time'] = time.time() - start_total\n",
    "    \n",
    "    # Print final match result\n",
    "    if final_results[\"top_match\"]:\n",
    "        print(\"\\n✨ Found a match on Amazon!\")\n",
    "        print(f\"   Title: {final_results['top_match']['title']}\")\n",
    "        if 'brand' in final_results['top_match']:\n",
    "            print(f\"   Brand: {final_results['top_match']['brand']}\")\n",
    "        if 'price' in final_results['top_match']:\n",
    "            print(f\"   Price: {final_results['top_match']['price']['raw']}\")\n",
    "        print(f\"   Link: {final_results['top_match']['link']}\")\n",
    "    else:\n",
    "        print(\"\\n❌ No suitable match found on Amazon\")\n",
    "    \n",
    "    # Print overall timing\n",
    "    print(f\"\\n⏱️ Total processing time: {timing['total_time']:.2f} seconds\")\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing image: tea.png...\n",
      "📷 Analyzing image with AI... \n",
      "✅ Image analyzed in 2.06s\n",
      "   Product: ITO EN Golden Oolong Tea\n",
      "   Size: 16.9 fl oz (500 mL)\n",
      "\n",
      "🔎 Searching Amazon for matching products...\n",
      "✅ Amazon search completed in 11.94s\n",
      "\n",
      "⚖️ Verifying matches...\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 3 column 19 (char 1531)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_product_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtea.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfw_3ZYLXEz2c3YWcN3CAkyaVedA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[14], line 69\u001b[0m, in \u001b[0;36mprocess_product_image\u001b[0;34m(image_path, api_key)\u001b[0m\n\u001b[1;32m     61\u001b[0m verification_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     62\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccounts/fireworks/models/mixtral-8x7b-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     messages\u001b[38;5;241m=\u001b[39mverification_messages,\n\u001b[1;32m     64\u001b[0m     response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     65\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Parse verification results\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m llm_verification \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverification_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m verification_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m verify_start\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Verification completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mverification_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:344\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:360\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 3 column 19 (char 1531)"
     ]
    }
   ],
   "source": [
    "results = process_product_image(\"tea.png\", \"fw_3ZYLXEz2c3YWcN3CAkyaVedA\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Search Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input parameters (as if from VLM analyzing a product image)\n",
    "search_parameters = {\n",
    "    \"product_name\": \"Pro-V Daily Moisture Renewal Shampoo\",\n",
    "    \"brand\": \"Pantene\",\n",
    "    \"attributes\": {\n",
    "        \"size\": \"25.4 fl oz\",\n",
    "        \"color\": \"white bottle with gold cap\",\n",
    "        \"description\": \"For dry hair\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import json\n",
    "# import requests\n",
    "\n",
    "# # Call the function with sample parameters\n",
    "# results = amazon_search(search_parameters)\n",
    "\n",
    "# # Print the results in a readable format\n",
    "# print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def simple_rainforest_test(api_key):\n",
    "    \"\"\"\n",
    "    Simple test of the Rainforest API using a basic search query\n",
    "    \"\"\"\n",
    "    # Base URL for Rainforest API\n",
    "    base_url = \"https://api.rainforestapi.com/request\"\n",
    "    \n",
    "    # Simple search parameters\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"type\": \"search\",\n",
    "        \"amazon_domain\": \"amazon.com\",\n",
    "        \"search_term\": \"iPhone charger\",  # Simple, common product\n",
    "        \"sort_by\": \"featured\"\n",
    "    }\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Return basic info about the results\n",
    "        result_summary = {\n",
    "            \"request_info\": data.get(\"request_info\", {}),\n",
    "            \"total_results\": len(data.get(\"search_results\", [])),\n",
    "            \"first_result\": data.get(\"search_results\", [{}])[0] if data.get(\"search_results\") else None\n",
    "        }\n",
    "        \n",
    "        return result_summary\n",
    "    else:\n",
    "        return {\n",
    "            \"error\": f\"Request failed with status code {response.status_code}\",\n",
    "            \"response\": response.text\n",
    "        }\n",
    "\n",
    "# # Example usage:\n",
    "# api_key = \"FB0C32E1DCB3433C997C0A0FB1E70608\"  # Replace with your actual API key\n",
    "# results = simple_rainforest_test(api_key)\n",
    "# print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
